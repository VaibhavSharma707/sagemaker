{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech-to-Text with Whisper Transfer Learning\n",
    "\n",
    "**Objective:** Fine-tune a Whisper base model on the United-Syn-Med dataset to improve medical speech transcription accuracy in a live teleconsultation context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:42:27.342392Z",
     "iopub.status.busy": "2025-06-17T09:42:27.342073Z",
     "iopub.status.idle": "2025-06-17T09:43:55.226107Z",
     "shell.execute_reply": "2025-06-17T09:43:55.225375Z",
     "shell.execute_reply.started": "2025-06-17T09:42:27.342371Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-rju39vv6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-rju39vv6\n",
      "  Resolved https://github.com/openai/whisper.git to commit dd985ac4b90cafeef8712f2998d62c59c3e62d22\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.6.0)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.9.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.6.0+cu124)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
      "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->openai-whisper==20240930) (2.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper==20240930) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->openai-whisper==20240930) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->openai-whisper==20240930) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->openai-whisper==20240930) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->openai-whisper==20240930) (2024.2.0)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803707 sha256=9d6e10d6e531bd068b05ff08e9aba96979d9f9d48e4d9b3fd24ac95084492c90\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-91ymx3a1/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\n",
      "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, fsspec, jiwer\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2025.3.0 jiwer-3.1.0 rapidfuzz-3.13.0\n"
     ]
    }
   ],
   "source": [
    "# Installing required packages\n",
    "\n",
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install jiwer datasets torchaudio transformers accelerate soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:43:55.227710Z",
     "iopub.status.busy": "2025-06-17T09:43:55.227456Z",
     "iopub.status.idle": "2025-06-17T09:44:21.499320Z",
     "shell.execute_reply": "2025-06-17T09:44:21.498523Z",
     "shell.execute_reply.started": "2025-06-17T09:43:55.227686Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 09:44:08.732191: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750153448.892769      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750153448.936656      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# import dependent libraries\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import whisper\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from datasets import Dataset, DatasetDict\n",
    "from jiwer import wer, cer\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, TrainingArguments, Trainer\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "import torchaudio\n",
    "from glob import glob\n",
    "from tqdm import tqdm  # for progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:46:05.717660Z",
     "iopub.status.busy": "2025-06-17T09:46:05.716763Z",
     "iopub.status.idle": "2025-06-17T09:46:05.743321Z",
     "shell.execute_reply": "2025-06-17T09:46:05.742671Z",
     "shell.execute_reply.started": "2025-06-17T09:46:05.717633Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/unitedsnymedsmall/unitedsynmed_small/transcript/validation.csv\n",
      "/kaggle/input/unitedsnymedsmall/unitedsynmed_small/transcript/train.csv\n",
      "/kaggle/input/unitedsnymedsmall/unitedsynmed_small/transcript/test.csv\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "n = 0\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        if n < 3:\n",
    "            print(os.path.join(dirname, filename))\n",
    "            n += 1\n",
    "        else: break\n",
    "    if n >= 3: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:46:06.450795Z",
     "iopub.status.busy": "2025-06-17T09:46:06.450199Z",
     "iopub.status.idle": "2025-06-17T09:46:06.589147Z",
     "shell.execute_reply": "2025-06-17T09:46:06.588540Z",
     "shell.execute_reply.started": "2025-06-17T09:46:06.450769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Paths to the dataset\n",
    "audio_root = \"/kaggle/input/unitedsnymedsmall/unitedsynmed_small/audio\"\n",
    "transcript_root = \"/kaggle/input/unitedsnymedsmall/unitedsynmed_small/transcript/\"\n",
    "\n",
    "# Load CSVs and match them with audio paths\n",
    "def load_split(split):\n",
    "    csv_path = os.path.join(transcript_root, f\"{split}.csv\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df[\"path\"] = df[\"file_name\"].apply(lambda x: os.path.join(audio_root, split, x))\n",
    "    return df\n",
    "\n",
    "# Create datasets\n",
    "train_df = load_split(\"train\")\n",
    "test_df = load_split(\"test\")\n",
    "val_df = load_split(\"validation\")\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df),\n",
    "    \"test\": Dataset.from_pandas(test_df),\n",
    "    \"validation\": Dataset.from_pandas(val_df)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:46:07.106166Z",
     "iopub.status.busy": "2025-06-17T09:46:07.105564Z",
     "iopub.status.idle": "2025-06-17T09:46:07.115009Z",
     "shell.execute_reply": "2025-06-17T09:46:07.114281Z",
     "shell.execute_reply.started": "2025-06-17T09:46:07.106131Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': ['drug-male-0b01f9d4-980d-451f-a8f1-18e899158859.wav',\n",
       "  'drug-male-d58aac86-05d3-40ea-a61d-e1cbb7f3e790.wav',\n",
       "  'drug-female-06c23421-e597-4cf4-a912-1d44c187a4f3.wav',\n",
       "  'drug-male-9300288f-77c3-4c42-a0f6-166877f7f965.wav',\n",
       "  'drug-female-86945722-12e1-4983-bf51-6aa27b196dc9.wav'],\n",
       " 'transcription': ['Iron calx is a commonly used medicine to treat iron deficiency anemia.',\n",
       "  'If you experience nausea or vomiting, DOMPAR may help alleviate your symptoms.',\n",
       "  'AGROBEN-I is a reliable medicine for treating infections in plants.',\n",
       "  \"Make sure to follow your healthcare provider's instructions carefully while taking FEVIBID for optimal results.\",\n",
       "  'Clinical trials have shown favorable results with maralixibat chloride in pediatric patients.'],\n",
       " 'path': ['/kaggle/input/unitedsnymedsmall/unitedsynmed_small/audio/train/drug-male-0b01f9d4-980d-451f-a8f1-18e899158859.wav',\n",
       "  '/kaggle/input/unitedsnymedsmall/unitedsynmed_small/audio/train/drug-male-d58aac86-05d3-40ea-a61d-e1cbb7f3e790.wav',\n",
       "  '/kaggle/input/unitedsnymedsmall/unitedsynmed_small/audio/train/drug-female-06c23421-e597-4cf4-a912-1d44c187a4f3.wav',\n",
       "  '/kaggle/input/unitedsnymedsmall/unitedsynmed_small/audio/train/drug-male-9300288f-77c3-4c42-a0f6-166877f7f965.wav',\n",
       "  '/kaggle/input/unitedsnymedsmall/unitedsynmed_small/audio/train/drug-female-86945722-12e1-4983-bf51-6aa27b196dc9.wav']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Whisper processor\n",
    "# processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\")\n",
    "\n",
    "# # Set target sample rate\n",
    "# target_sample_rate = 16000\n",
    "\n",
    "# def preprocess(batch):\n",
    "#     audio_input, sr = sf.read(batch[\"path\"])\n",
    "    \n",
    "#     # If the sample rate is not 16kHz, resample it\n",
    "#     # if sr != target_sample_rate:\n",
    "#     waveform = torch.tensor(audio_input, dtype=torch.float32).float().to(device) \n",
    "#     if len(waveform.shape) > 1 and waveform.shape[0] > 1:\n",
    "#         waveform = waveform.mean(dim=0)  # Convert to mono\n",
    "#     resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sample_rate).to(device)\n",
    "#     audio_input = resampler(waveform).cpu().numpy()\n",
    "    \n",
    "#     inputs = processor(audio_input, sampling_rate=target_sample_rate, return_tensors=\"pt\").to(device)\n",
    "#     batch[\"input_features\"] = inputs.input_features[0].to\n",
    "#     batch[\"labels\"] = processor.tokenizer(batch[\"transcription\"]).input_ids\n",
    "#     return batch\n",
    "\n",
    "# # Apply preprocessing\n",
    "# dataset = dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:46:07.400534Z",
     "iopub.status.busy": "2025-06-17T09:46:07.399864Z",
     "iopub.status.idle": "2025-06-17T09:46:07.403879Z",
     "shell.execute_reply": "2025-06-17T09:46:07.403242Z",
     "shell.execute_reply.started": "2025-06-17T09:46:07.400512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:46:08.071419Z",
     "iopub.status.busy": "2025-06-17T09:46:08.070711Z",
     "iopub.status.idle": "2025-06-17T09:46:08.075457Z",
     "shell.execute_reply": "2025-06-17T09:46:08.074593Z",
     "shell.execute_reply.started": "2025-06-17T09:46:08.071394Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:46:10.010662Z",
     "iopub.status.busy": "2025-06-17T09:46:10.009768Z",
     "iopub.status.idle": "2025-06-17T09:51:38.255131Z",
     "shell.execute_reply": "2025-06-17T09:51:38.254143Z",
     "shell.execute_reply.started": "2025-06-17T09:46:10.010622Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a323f3af78f54a0184b06be3f726e347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1240089e36546b3b4a439574511f87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6934689b97b4487ac6b078a59d4077c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fe190aa5514d8396d52b1218b4165e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25a8ca02fbf470e861b7df337a91f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0784e9d9e2724fbcbf13fa38f4dea340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5206bfec48dc4445a0038ef70ac49906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c873bdc1d804971b6279fff0312b59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bd1e275491400781927f7f1aa85f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d93648152f54148bfdbbe64589dcf50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d55040c6b5494a88be0ca10e7cf202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torchaudio\n",
    "from transformers import WhisperProcessor\n",
    "import torch\n",
    "\n",
    "# Initialize processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def preprocess(batch):\n",
    "    \n",
    "    # 1. Load audio file\n",
    "    waveform, sr = torchaudio.load(batch[\"path\"])\n",
    "    waveform = waveform.to(device)  # Move to GPU here\n",
    "    \n",
    "    # 2. Verify sample rate (optional if you're certain)\n",
    "    if sr != 16000:\n",
    "        raise ValueError(f\"Invalid sample rate {sr}Hz (expected 16000Hz)\")\n",
    "    \n",
    "    # 3. Convert to mono if needed\n",
    "    if waveform.dim() > 1 and waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    # 4. Process audio - key fix is making sure we use the tensor, not the method\n",
    "    audio_array = waveform.squeeze().cpu().numpy()  # Explicitly move to CPU first\n",
    "    \n",
    "    # 5. Generate features\n",
    "    inputs = processor(\n",
    "        audio_array,\n",
    "        sampling_rate=16000,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # 6. Prepare output - ensure we're using the actual tensors\n",
    "    batch[\"input_features\"] = inputs.input_features[0].numpy()  # Convert to numpy array\n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"transcription\"]).input_ids\n",
    "    batch[\"input_features\"] = inputs.input_features[0].cpu().numpy()\n",
    "    \n",
    "    return batch\n",
    "        \n",
    "\n",
    "# Apply preprocessing\n",
    "dataset = dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:52:25.132358Z",
     "iopub.status.busy": "2025-06-17T09:52:25.132013Z",
     "iopub.status.idle": "2025-06-17T09:52:25.141406Z",
     "shell.execute_reply": "2025-06-17T09:52:25.140708Z",
     "shell.execute_reply.started": "2025-06-17T09:52:25.132336Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    apply_spec_augment: bool = True\n",
    "    apply_noise: bool = True\n",
    "\n",
    "    def __call__(self, features):\n",
    "        # 1. Pad input features and labels\n",
    "        input_features = [{\"input_features\": f[\"input_features\"]} for f in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "        \n",
    "        # 2. Apply SpecAugment (correct implementation)\n",
    "        if self.apply_spec_augment:\n",
    "            # Time masking\n",
    "            time_masked = batch[\"input_features\"].clone()\n",
    "            time_mask_length = torch.randint(low=0, high=30, size=(1,)).item()\n",
    "            time_mask_start = torch.randint(low=0, high=max(1, batch[\"input_features\"].shape[1] - time_mask_length), size=(1,)).item()\n",
    "            time_masked[:, time_mask_start:time_mask_start+time_mask_length, :] = 0\n",
    "            \n",
    "            # Frequency masking\n",
    "            freq_masked = time_masked.clone()\n",
    "            freq_mask_length = torch.randint(low=0, high=10, size=(1,)).item()\n",
    "            freq_mask_start = torch.randint(low=0, high=max(1, batch[\"input_features\"].shape[2] - freq_mask_length), size=(1,)).item()\n",
    "            freq_masked[:, :, freq_mask_start:freq_mask_start+freq_mask_length] = 0\n",
    "            \n",
    "            batch[\"input_features\"] = freq_masked\n",
    "        \n",
    "        # 3. Add Gaussian noise\n",
    "        if self.apply_noise and torch.rand(1) < 0.05:\n",
    "            batch[\"input_features\"] += torch.randn_like(batch[\"input_features\"]) * 0.01\n",
    "        \n",
    "        # 4. Normalize\n",
    "        batch[\"input_features\"] = (batch[\"input_features\"] - batch[\"input_features\"].mean()) / (batch[\"input_features\"].std() + 1e-7)\n",
    "        \n",
    "        # 5. Process labels\n",
    "        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch[\"input_ids\"] == self.processor.tokenizer.pad_token_id, -100)\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:52:27.716136Z",
     "iopub.status.busy": "2025-06-17T09:52:27.715843Z",
     "iopub.status.idle": "2025-06-17T09:52:30.306836Z",
     "shell.execute_reply": "2025-06-17T09:52:30.306082Z",
     "shell.execute_reply.started": "2025-06-17T09:52:27.716116Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08a968eaa6f4e67a708e843c21fbce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.98k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9929757a885a4930a0d7277567aae99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4e09dc5fee42b1b5ab066f8cf84000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from transformers import WhisperForConditionalGeneration, Seq2SeqTrainingArguments, TrainerCallback, Trainer\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# 1. Load base Whisper model\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:52:30.308196Z",
     "iopub.status.busy": "2025-06-17T09:52:30.307943Z",
     "iopub.status.idle": "2025-06-17T09:52:30.312529Z",
     "shell.execute_reply": "2025-06-17T09:52:30.311829Z",
     "shell.execute_reply.started": "2025-06-17T09:52:30.308178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2. Freeze encoder except last 2 layers (optional fine-tuning strategy)\n",
    "for param in model.model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "for layer in model.model.encoder.layers[-2:]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:52:30.313511Z",
     "iopub.status.busy": "2025-06-17T09:52:30.313263Z",
     "iopub.status.idle": "2025-06-17T09:52:30.324740Z",
     "shell.execute_reply": "2025-06-17T09:52:30.324012Z",
     "shell.execute_reply.started": "2025-06-17T09:52:30.313490Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3. Define compute_metrics\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # Limit to first 100 samples to reduce memory usage\n",
    "    max_samples = 100\n",
    "    pred_ids = pred_ids[:max_samples]\n",
    "    label_ids = label_ids[:max_samples]\n",
    "    \n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    wer_score = wer(label_str, pred_str)\n",
    "    cer_score = cer(label_str, pred_str)\n",
    "    \n",
    "    return {\"eval_loss\": wer_score, \"eval_cer\": cer_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:52:31.073350Z",
     "iopub.status.busy": "2025-06-17T09:52:31.072748Z",
     "iopub.status.idle": "2025-06-17T09:52:31.077265Z",
     "shell.execute_reply": "2025-06-17T09:52:31.076496Z",
     "shell.execute_reply.started": "2025-06-17T09:52:31.073323Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 4. Clear memory callback\n",
    "class ClearMemoryCallback(TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:52:31.412466Z",
     "iopub.status.busy": "2025-06-17T09:52:31.411670Z",
     "iopub.status.idle": "2025-06-17T09:52:32.228902Z",
     "shell.execute_reply": "2025-06-17T09:52:32.228365Z",
     "shell.execute_reply.started": "2025-06-17T09:52:31.412440Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 5. Create logging directory\n",
    "os.makedirs(\"./logs\", exist_ok=True)\n",
    "\n",
    "# 6. Set label names for Trainer\n",
    "if hasattr(model, 'config'):\n",
    "    model.config.label_names = [\"labels\"]\n",
    "    \n",
    "# 7. Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-medical-v2\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=3e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"tensorboard\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    remove_unused_columns=False,\n",
    "    eval_accumulation_steps=2,\n",
    "    prediction_loss_only=True\n",
    ")\n",
    "\n",
    "# 8. Data collator\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "# 9. Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"].with_format(\"torch\"),\n",
    "    eval_dataset=dataset[\"validation\"].with_format(\"torch\"),\n",
    "    processing_class=processor,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[ClearMemoryCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:52:33.566219Z",
     "iopub.status.busy": "2025-06-17T09:52:33.565709Z",
     "iopub.status.idle": "2025-06-17T09:52:33.570425Z",
     "shell.execute_reply": "2025-06-17T09:52:33.569679Z",
     "shell.execute_reply.started": "2025-06-17T09:52:33.566196Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True\n",
      "Device being used: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Confirm GPU is being used\n",
    "\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device being used: {trainer.args.device}\")  # After creating trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T09:52:45.315670Z",
     "iopub.status.busy": "2025-06-17T09:52:45.315228Z",
     "iopub.status.idle": "2025-06-17T10:47:24.987231Z",
     "shell.execute_reply": "2025-06-17T10:47:24.986592Z",
     "shell.execute_reply.started": "2025-06-17T09:52:45.315632Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5940' max='5940' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5940/5940 54:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.968400</td>\n",
       "      <td>2.700359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.176000</td>\n",
       "      <td>2.230670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.728400</td>\n",
       "      <td>2.032025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.382300</td>\n",
       "      <td>1.907453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.140900</td>\n",
       "      <td>1.845043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.934200</td>\n",
       "      <td>1.783167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.773300</td>\n",
       "      <td>1.757256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>1.750147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.561500</td>\n",
       "      <td>1.750251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.524000</td>\n",
       "      <td>1.759988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5940, training_loss=1.439986103391808, metrics={'train_runtime': 3279.2, 'train_samples_per_second': 28.97, 'train_steps_per_second': 1.811, 'total_flos': 6.1616996352e+18, 'train_loss': 1.439986103391808, 'epoch': 10.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Model\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T10:47:41.481018Z",
     "iopub.status.busy": "2025-06-17T10:47:41.480428Z",
     "iopub.status.idle": "2025-06-17T10:47:42.583934Z",
     "shell.execute_reply": "2025-06-17T10:47:42.583255Z",
     "shell.execute_reply.started": "2025-06-17T10:47:41.480998Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Model\n",
    "\n",
    "trainer.save_model(\"./whisper-medical-v2-final\")\n",
    "processor.save_pretrained(\"./whisper-medical-v2-final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Reload model\n",
    "\n",
    "# from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
    "\n",
    "# model = WhisperForConditionalGeneration.from_pretrained(\"./whisper-medical-v2-final\")\n",
    "# processor = WhisperProcessor.from_pretrained(\"./whisper-medical-v2-final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T10:48:44.350045Z",
     "iopub.status.busy": "2025-06-17T10:48:44.349493Z",
     "iopub.status.idle": "2025-06-17T10:49:17.577604Z",
     "shell.execute_reply": "2025-06-17T10:49:17.576968Z",
     "shell.execute_reply.started": "2025-06-17T10:48:44.350024Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7540605068206787, 'eval_runtime': 33.2195, 'eval_samples_per_second': 36.123, 'eval_steps_per_second': 18.062, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T10:52:39.971044Z",
     "iopub.status.busy": "2025-06-17T10:52:39.970232Z",
     "iopub.status.idle": "2025-06-17T10:53:07.023981Z",
     "shell.execute_reply": "2025-06-17T10:53:07.023413Z",
     "shell.execute_reply.started": "2025-06-17T10:52:39.971017Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/whisper-medical-v2-final.zip'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the saved model\n",
    "import shutil\n",
    "\n",
    "# Zip the model directory\n",
    "shutil.make_archive(\"whisper-medical-v2-final\", 'zip', \"./whisper-medical-v2-final\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the trained model on a single audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:10:59.215604Z",
     "iopub.status.busy": "2025-06-17T11:10:59.215284Z",
     "iopub.status.idle": "2025-06-17T11:10:59.332739Z",
     "shell.execute_reply": "2025-06-17T11:10:59.332146Z",
     "shell.execute_reply.started": "2025-06-17T11:10:59.215584Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on: /kaggle/input/unitedsnymedsmall/unitedsynmed_small/audio/test/drug-male-2879b019-a935-4a3e-98fc-0617ce82a124.wav\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from transformers import pipeline\n",
    "\n",
    "# 1. Load audio file correctly\n",
    "test_file = dataset[\"test\"][215][\"path\"]  # or your custom path\n",
    "print(f\"Testing on: {test_file}\")\n",
    "waveform, sample_rate = torchaudio.load(test_file)\n",
    "\n",
    "# 2. Convert to mono if needed and resample\n",
    "if waveform.shape[0] > 1:  # If multi-channel\n",
    "    waveform = waveform.mean(dim=0, keepdim=True)  # Convert to mono\n",
    "    \n",
    "if sample_rate != 16000:\n",
    "    resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
    "    waveform = resampler(waveform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:11:25.183248Z",
     "iopub.status.busy": "2025-06-17T11:11:25.182968Z",
     "iopub.status.idle": "2025-06-17T11:11:25.187181Z",
     "shell.execute_reply": "2025-06-17T11:11:25.186436Z",
     "shell.execute_reply.started": "2025-06-17T11:11:25.183227Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 3. Prepare input format (single channel, numpy array)\n",
    "audio_input = waveform.squeeze().numpy()  # Must be 1D numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:11:49.932542Z",
     "iopub.status.busy": "2025-06-17T11:11:49.932299Z",
     "iopub.status.idle": "2025-06-17T11:11:49.938469Z",
     "shell.execute_reply": "2025-06-17T11:11:49.937873Z",
     "shell.execute_reply.started": "2025-06-17T11:11:49.932526Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 4. Create ASR pipeline with trained model\n",
    "asr_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:12:04.794807Z",
     "iopub.status.busy": "2025-06-17T11:12:04.794126Z",
     "iopub.status.idle": "2025-06-17T11:12:11.493683Z",
     "shell.execute_reply": "2025-06-17T11:12:11.493131Z",
     "shell.execute_reply.started": "2025-06-17T11:12:04.794786Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
      "WhisperModel is using WhisperSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `layer_head_mask` not None. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    }
   ],
   "source": [
    "# 5. Run inference\n",
    "results = asr_pipe(\n",
    "    audio_input,  # 1D numpy array\n",
    "    return_timestamps=\"word\",\n",
    "    generate_kwargs={\n",
    "        \"language\": \"en\",\n",
    "        \"task\": \"transcribe\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:12:26.458942Z",
     "iopub.status.busy": "2025-06-17T11:12:26.458640Z",
     "iopub.status.idle": "2025-06-17T11:12:26.463939Z",
     "shell.execute_reply": "2025-06-17T11:12:26.463290Z",
     "shell.execute_reply.started": "2025-06-17T11:12:26.458911Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:\n",
      " Make sure to take Telmaze-ED exactly as prescribed by your healthcare provider.                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "Timestamps:\n",
      "(0.26, 0.38):  Make\n",
      "(0.38, 0.64):  sure\n",
      "(0.64, 0.82):  to\n",
      "(0.82, 1.04):  take\n",
      "(1.04, 1.64):  Telmaze\n",
      "(1.64, 2.18): -ED\n",
      "(2.18, 2.66):  exactly\n",
      "(2.66, 3.12):  as\n",
      "(3.12, 3.58):  prescribed\n",
      "(3.58, 3.96):  by\n",
      "(3.96, 4.16):  your\n",
      "(4.16, 4.6):  healthcare\n",
      "(4.6, 5.6):  provider.\n",
      "(5.6, None):                                                                                                                                                                                                                                                                                                                                                                                                                                            \n"
     ]
    }
   ],
   "source": [
    "# 6. Print results\n",
    "print(\"Transcription:\")\n",
    "print(results[\"text\"])\n",
    "\n",
    "if \"chunks\" in results:\n",
    "    print(\"\\nTimestamps:\")\n",
    "    for chunk in results[\"chunks\"]:\n",
    "        print(f\"{chunk['timestamp']}: {chunk['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:14:35.027920Z",
     "iopub.status.busy": "2025-06-17T11:14:35.027650Z",
     "iopub.status.idle": "2025-06-17T11:14:39.027929Z",
     "shell.execute_reply": "2025-06-17T11:14:39.027133Z",
     "shell.execute_reply.started": "2025-06-17T11:14:35.027900Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.13.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:14:43.050723Z",
     "iopub.status.busy": "2025-06-17T11:14:43.050423Z",
     "iopub.status.idle": "2025-06-17T11:14:44.627635Z",
     "shell.execute_reply": "2025-06-17T11:14:44.626905Z",
     "shell.execute_reply.started": "2025-06-17T11:14:43.050697Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54319f1ad4443508efea9ad0b80b63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WER: 8.33%\n",
      "Reference: Make sure to take TELMA-ACT exactly as prescribed by your healthcare provider.\n"
     ]
    }
   ],
   "source": [
    "# Get reference transcription\n",
    "reference = dataset[\"test\"][215][\"transcription\"]\n",
    "\n",
    "# Calculate WER\n",
    "from evaluate import load\n",
    "wer = load(\"wer\")\n",
    "print(f\"\\nWER: {100 * wer.compute(predictions=[results['text']], references=[reference]):.2f}%\")\n",
    "print(f\"Reference: {reference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T11:28:43.974589Z",
     "iopub.status.busy": "2025-06-17T11:28:43.973864Z",
     "iopub.status.idle": "2025-06-17T11:36:31.210864Z",
     "shell.execute_reply": "2025-06-17T11:36:31.210123Z",
     "shell.execute_reply.started": "2025-06-17T11:28:43.974566Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/whisper-medical-v2.zip'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the trained model folder\n",
    "import shutil\n",
    "\n",
    "# Zip the model directory\n",
    "shutil.make_archive(\"whisper-medical-v2\", 'zip', \"./whisper-medical-v2\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7662794,
     "sourceId": 12166578,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
