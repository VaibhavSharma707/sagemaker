{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T02:28:28.319509Z",
     "iopub.status.busy": "2025-06-16T02:28:28.319186Z",
     "iopub.status.idle": "2025-06-16T02:28:32.276728Z",
     "shell.execute_reply": "2025-06-16T02:28:32.275911Z",
     "shell.execute_reply.started": "2025-06-16T02:28:28.319488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q ultralytics\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T02:28:49.008601Z",
     "iopub.status.busy": "2025-06-16T02:28:49.008263Z",
     "iopub.status.idle": "2025-06-16T02:29:51.422862Z",
     "shell.execute_reply": "2025-06-16T02:29:51.422053Z",
     "shell.execute_reply.started": "2025-06-16T02:28:49.008571Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total usable images: 31645, Skipped: 0\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/kaggle/input/dataset256/UECFOOD256'\n",
    "out_img_dir = '/kaggle/working/dataset/images'\n",
    "out_lbl_dir = '/kaggle/working/dataset/labels'\n",
    "for split in ['train', 'val', 'test']:\n",
    "    os.makedirs(f'{out_img_dir}/{split}', exist_ok=True)\n",
    "    os.makedirs(f'{out_lbl_dir}/{split}', exist_ok=True)\n",
    "\n",
    "image_label_pairs = []\n",
    "skipped = 0\n",
    "\n",
    "for class_id in range(1, 257):\n",
    "    class_path = os.path.join(root_dir, str(class_id))\n",
    "    bbox_file = os.path.join(class_path, \"bb_info.txt\")\n",
    "\n",
    "    if not os.path.exists(bbox_file):\n",
    "        continue\n",
    "\n",
    "    with open(bbox_file, 'r') as f:\n",
    "        lines = f.readlines()[1:]\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 5:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        img_name, x1, y1, x2, y2 = parts\n",
    "        try:\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        except:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(class_path, f\"{img_name}.jpg\")\n",
    "        if not os.path.exists(img_path):\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                w, h = img.size\n",
    "        except:\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        xc = ((x1 + x2) / 2) / w\n",
    "        yc = ((y1 + y2) / 2) / h\n",
    "        bw = (x2 - x1) / w\n",
    "        bh = (y2 - y1) / h\n",
    "\n",
    "        new_name = f\"{class_id}_{img_name}.jpg\"\n",
    "        label = class_id - 1\n",
    "        image_label_pairs.append((img_path, new_name, label, xc, yc, bw, bh))\n",
    "\n",
    "print(f\"âœ… Total usable images: {len(image_label_pairs)}, Skipped: {skipped}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T02:30:34.810162Z",
     "iopub.status.busy": "2025-06-16T02:30:34.809496Z",
     "iopub.status.idle": "2025-06-16T02:31:16.685765Z",
     "shell.execute_reply": "2025-06-16T02:31:16.685105Z",
     "shell.execute_reply.started": "2025-06-16T02:30:34.810138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train, temp = train_test_split(image_label_pairs, test_size=0.3, random_state=42)\n",
    "val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "def save_data(split, name):\n",
    "    for img_path, fname, cls, xc, yc, bw, bh in split:\n",
    "        shutil.copy(img_path, f\"{out_img_dir}/{name}/{fname}\")\n",
    "        with open(f\"{out_lbl_dir}/{name}/{fname.replace('.jpg', '.txt')}\", \"w\") as f:\n",
    "            f.write(f\"{cls} {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
    "\n",
    "save_data(train, 'train')\n",
    "save_data(val, 'val')\n",
    "save_data(test, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T02:32:12.050115Z",
     "iopub.status.busy": "2025-06-16T02:32:12.049795Z",
     "iopub.status.idle": "2025-06-16T02:32:12.055377Z",
     "shell.execute_reply": "2025-06-16T02:32:12.054640Z",
     "shell.execute_reply.started": "2025-06-16T02:32:12.050092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# cat_map = {}\n",
    "# with open('/kaggle/input/dataset256/UECFOOD256/category.txt', 'r') as f:\n",
    "#     for line in f:\n",
    "#         try:\n",
    "#             idx, name = line.strip().split(maxsplit=1)\n",
    "#             cat_map[int(idx) - 1] = name.strip()\n",
    "#         except:\n",
    "#             continue\n",
    "\n",
    "# Now write dataset.yaml\n",
    "# with open(\"dataset.yaml\", \"w\") as f:\n",
    "#     f.write(\"path: /kaggle/working/dataset\\n\")\n",
    "#     f.write(\"train: images/train\\n\")\n",
    "#     f.write(\"val: images/train\\n\")\n",
    "#     f.write(\"names:\\n\")\n",
    "#     for i in range(256):\n",
    "#         f.write(f\"  {i}: {cat_map.get(i, f'food_{i}')}\\n\")\n",
    "\n",
    "with open('/kaggle/working/dataset.yaml', 'w') as f:\n",
    "    f.write(f\"\"\"\n",
    "path: /kaggle/working/dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "nc: 256\n",
    "names: [{', '.join([f'\"class_{i}\"' for i in range(256)])}]\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T02:32:23.427596Z",
     "iopub.status.busy": "2025-06-16T02:32:23.427315Z",
     "iopub.status.idle": "2025-06-16T04:32:16.944990Z",
     "shell.execute_reply": "2025-06-16T04:32:16.944132Z",
     "shell.execute_reply.started": "2025-06-16T02:32:23.427575Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.155 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/dataset.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=416, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=uec256_kaggle, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/uec256_kaggle, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=256\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     74240  ultralytics.nn.modules.conv.Conv             [32, 256, 3, 2]               \n",
      "  4                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  5                  -1  1    295168  ultralytics.nn.modules.conv.Conv             [256, 128, 3, 2]              \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   3936976  ultralytics.nn.modules.head.Detect           [256, [256, 128, 256]]        \n",
      "Model summary: 129 layers, 8,245,920 parameters, 8,245,904 gradients, 46.8 GFLOPs\n",
      "\n",
      "Transferred 256/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1175.8Â±662.5 MB/s, size: 106.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/labels/train... 31395 images, 0 backgrounds, 1 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31395/31395 [00:21<00:00, 1466.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/150_37571.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.3262]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/16_1581.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/16_1585.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/1_81.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/1_85.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/1_87.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/1_98.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/30_2902.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/35_3394.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/36_82.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/36_84.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/36_99.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/40_83.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/43_4212.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/43_4232.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/44_4334.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/51_5171.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/52_5251.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/58_5854.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/67_86.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/73_7786.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/81_8633.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/82_8677.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/86_11783.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/86_11784.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/86_11789.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/86_82.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/88_86.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/89_12078.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/89_81.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/89_83.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/91_12291.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/95_12699.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/95_12716.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/99_83.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/99_86.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/99_99.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/labels/train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 381.3Â±119.4 MB/s, size: 124.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/labels/val... 4737 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4737/4737 [00:03<00:00, 1410.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/images/val/36_87.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/dataset/images/val/45_4440.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dataset/labels/val.cache\n",
      "Plotting labels to /kaggle/working/uec256_kaggle/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=3.8e-05, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/kaggle/working/uec256_kaggle\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20      5.03G      1.363      5.078      1.587          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:40<00:00,  5.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:27<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737    0.00454      0.539    0.00679     0.0053\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20      5.05G     0.9871      4.208      1.278          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:31<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.297     0.0905     0.0235     0.0172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20      5.09G      0.937      3.679      1.241          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:27<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.556     0.0934     0.0677     0.0506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20      5.12G     0.9147      3.418      1.224          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:26<00:00,  6.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.386      0.148      0.111     0.0819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20      5.13G     0.8943      3.243      1.213          7        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:26<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.343      0.203      0.148       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20      5.17G     0.8824      3.112      1.206          3        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:26<00:00,  6.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.337      0.248      0.196      0.146\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20       5.2G     0.8721      3.014      1.201          4        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:26<00:00,  6.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.343      0.282      0.232      0.173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20      5.22G     0.8647      2.926      1.198          5        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:26<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.332      0.307       0.26      0.195\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20      5.24G     0.8593      2.851      1.195          7        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:26<00:00,  6.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.323      0.338      0.289      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20      5.28G     0.8568      2.786      1.194          6        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:27<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:27<00:00,  5.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.344      0.359      0.323      0.243\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20       5.3G     0.7741      2.616       1.25          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:23<00:00,  6.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.354      0.401      0.352      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20      5.33G     0.7568      2.467      1.237          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:23<00:00,  6.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.381      0.414      0.383      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20      5.35G     0.7541      2.386      1.235          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:23<00:00,  6.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:27<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.406      0.434       0.41      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20      5.38G     0.7454      2.327      1.226          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:23<00:00,  6.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.436      0.434      0.426      0.328\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20      5.41G     0.7456      2.273       1.23          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:23<00:00,  6.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.447      0.454      0.444      0.343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20      5.44G     0.7405      2.227      1.223          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:23<00:00,  6.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.452      0.461      0.454      0.351\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20      5.45G     0.7355      2.186      1.223          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:24<00:00,  6.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.465      0.461      0.464      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20      5.49G     0.7318      2.157      1.221          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:23<00:00,  6.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.467      0.474      0.471      0.365\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20      5.52G     0.7323      2.134      1.218          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:23<00:00,  6.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.488      0.472      0.478       0.37\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20      5.54G     0.7287      2.113      1.216          2        416: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1963/1963 [05:23<00:00,  6.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:28<00:00,  5.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.484      0.473      0.481      0.372\n",
      "\n",
      "20 epochs completed in 1.979 hours.\n",
      "Optimizer stripped from /kaggle/working/uec256_kaggle/weights/last.pt, 16.7MB\n",
      "Optimizer stripped from /kaggle/working/uec256_kaggle/weights/best.pt, 16.7MB\n",
      "\n",
      "Validating /kaggle/working/uec256_kaggle/weights/best.pt...\n",
      "Ultralytics 8.3.155 ðŸš€ Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 72 layers, 8,237,840 parameters, 0 gradients, 46.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 149/149 [00:27<00:00,  5.51it/s]\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4737       4737      0.482      0.474       0.48      0.371\n",
      "               class_0         92         92      0.303      0.663      0.392      0.294\n",
      "               class_1         18         18      0.552      0.944      0.887      0.668\n",
      "               class_2         17         17        0.4      0.412      0.468      0.274\n",
      "               class_3         19         19      0.355      0.318      0.335      0.272\n",
      "               class_4         18         18      0.436      0.722      0.566      0.416\n",
      "               class_5         35         35      0.603      0.714      0.733      0.564\n",
      "               class_6         30         30      0.661      0.433      0.602      0.445\n",
      "               class_7         13         13      0.619      0.462      0.375      0.298\n",
      "               class_8         29         29       0.54      0.759      0.698      0.466\n",
      "               class_9         19         19      0.648      0.737       0.77       0.63\n",
      "              class_10         16         16      0.554      0.701      0.805      0.727\n",
      "              class_11         40         40      0.564      0.525      0.536      0.408\n",
      "              class_12         18         18      0.405      0.333      0.359      0.233\n",
      "              class_13         16         16      0.396      0.312      0.339      0.265\n",
      "              class_14         15         15      0.303      0.333      0.417      0.342\n",
      "              class_15         16         16      0.187     0.0625     0.0818     0.0637\n",
      "              class_16         39         39      0.752      0.795      0.814      0.635\n",
      "              class_17         23         23      0.662      0.783       0.73      0.633\n",
      "              class_18         27         27      0.601      0.667        0.7      0.526\n",
      "              class_19         29         29      0.491      0.724      0.748       0.63\n",
      "              class_20         18         18      0.505      0.389      0.447      0.278\n",
      "              class_21         21         21      0.584      0.952      0.927      0.753\n",
      "              class_22         52         52       0.52      0.692      0.623      0.473\n",
      "              class_23         24         24      0.542      0.458      0.522      0.386\n",
      "              class_24         15         15      0.735      0.733      0.821      0.611\n",
      "              class_25         22         22      0.485      0.364      0.437      0.281\n",
      "              class_26         16         16      0.182      0.251      0.205      0.125\n",
      "              class_27         21         21      0.825      0.714      0.866      0.666\n",
      "              class_28         12         12      0.618      0.667      0.726      0.533\n",
      "              class_29         24         24      0.778       0.75      0.784      0.626\n",
      "              class_30         18         18          0          0     0.0685     0.0397\n",
      "              class_31         21         21      0.539      0.429      0.453      0.362\n",
      "              class_32         13         13          1          0     0.0554     0.0441\n",
      "              class_33         18         18      0.457      0.722       0.75      0.552\n",
      "              class_34         16         16      0.473      0.375       0.37      0.249\n",
      "              class_35        112        112      0.358      0.732      0.503      0.369\n",
      "              class_36         20         20      0.842        0.9      0.907      0.731\n",
      "              class_37         16         16      0.852      0.312      0.388      0.227\n",
      "              class_38         19         19      0.777      0.366      0.512       0.32\n",
      "              class_39         15         15       0.49        0.4      0.389      0.287\n",
      "              class_40         16         16          1          0       0.18      0.134\n",
      "              class_41         20         20       0.41        0.4      0.325      0.192\n",
      "              class_42         12         12      0.792       0.32      0.543       0.36\n",
      "              class_43          9          9      0.445      0.333      0.351      0.205\n",
      "              class_44         17         17      0.743      0.172      0.222      0.121\n",
      "              class_45         17         17      0.707      0.529      0.591      0.374\n",
      "              class_46         17         17      0.281      0.118       0.19      0.124\n",
      "              class_47         24         24      0.287      0.417      0.345      0.254\n",
      "              class_48         26         26      0.425      0.769      0.648      0.349\n",
      "              class_49         20         20        0.5       0.15      0.387      0.304\n",
      "              class_50         19         19      0.541      0.526      0.598      0.422\n",
      "              class_51         15         15      0.152        0.2      0.146        0.1\n",
      "              class_52         22         22      0.487      0.455       0.48      0.305\n",
      "              class_53         22         22       0.45      0.364      0.408      0.317\n",
      "              class_54         17         17      0.424      0.235      0.245      0.156\n",
      "              class_55         23         23      0.459      0.435      0.453      0.365\n",
      "              class_56         15         15      0.169     0.0678      0.185     0.0955\n",
      "              class_57         16         16      0.579      0.438      0.475      0.259\n",
      "              class_58         18         18      0.691      0.497      0.595      0.448\n",
      "              class_59         21         21      0.389      0.334       0.44      0.274\n",
      "              class_60         16         16      0.398      0.438      0.387      0.241\n",
      "              class_61         13         13      0.397      0.769      0.561      0.453\n",
      "              class_62         21         21      0.857     0.0952      0.284      0.213\n",
      "              class_63         18         18      0.421      0.123      0.272       0.22\n",
      "              class_64         16         16      0.519      0.438      0.571      0.286\n",
      "              class_65         16         16      0.546        0.5      0.587      0.365\n",
      "              class_66         22         22       0.39      0.262      0.356      0.297\n",
      "              class_67         32         32      0.527        0.5      0.564      0.363\n",
      "              class_68         26         26      0.459      0.269      0.354      0.221\n",
      "              class_69         25         25      0.367       0.28      0.199      0.121\n",
      "              class_70         16         16        0.5       0.25      0.328      0.234\n",
      "              class_71         21         21      0.761      0.757      0.848      0.719\n",
      "              class_72         26         26      0.707      0.692      0.754      0.514\n",
      "              class_73         20         20      0.638       0.25      0.419      0.233\n",
      "              class_74         12         12      0.263       0.25      0.262      0.137\n",
      "              class_75         21         21      0.516      0.476      0.596      0.527\n",
      "              class_76         13         13      0.469      0.342      0.532      0.353\n",
      "              class_77         19         19      0.534      0.632      0.627      0.516\n",
      "              class_78         22         22      0.684        0.5      0.645      0.439\n",
      "              class_79         14         14      0.418      0.214      0.381      0.304\n",
      "              class_80         21         21       0.67      0.238      0.353      0.208\n",
      "              class_81         20         20      0.629        0.4       0.44      0.311\n",
      "              class_82         24         24      0.437      0.582      0.541      0.459\n",
      "              class_83         16         16      0.868      0.688      0.818      0.652\n",
      "              class_84         21         21      0.549      0.524      0.587      0.391\n",
      "              class_85         12         12      0.284        0.5      0.401      0.307\n",
      "              class_86         63         63      0.275      0.302      0.255      0.194\n",
      "              class_87         12         12       0.62      0.667      0.633      0.494\n",
      "              class_88         14         14      0.402      0.337      0.199      0.138\n",
      "              class_89         14         14      0.357      0.214      0.244      0.205\n",
      "              class_90         26         26      0.634      0.115      0.307      0.257\n",
      "              class_91         30         30      0.487      0.567      0.531      0.407\n",
      "              class_92         20         20      0.516       0.25      0.437      0.304\n",
      "              class_93         31         31      0.421      0.387      0.351      0.253\n",
      "              class_94         13         13       0.55       0.66      0.757      0.542\n",
      "              class_95         25         25      0.462       0.68      0.603      0.422\n",
      "              class_96         16         16      0.559      0.625      0.674      0.463\n",
      "              class_97         28         28      0.496      0.464      0.463      0.293\n",
      "              class_98         18         18       0.29      0.167      0.273      0.195\n",
      "              class_99         17         17      0.471      0.471      0.554      0.389\n",
      "             class_100         15         15      0.537        0.2      0.294      0.242\n",
      "             class_101         23         23      0.564       0.87      0.755      0.671\n",
      "             class_102         16         16      0.467      0.657      0.483      0.405\n",
      "             class_103         25         25      0.581       0.76      0.692      0.542\n",
      "             class_104         22         22      0.699      0.818      0.771      0.545\n",
      "             class_105         20         20      0.686        0.7      0.724      0.525\n",
      "             class_106         21         21      0.848      0.532      0.705      0.582\n",
      "             class_107         13         13       0.64      0.769      0.769      0.501\n",
      "             class_108         20         20      0.765      0.165      0.352      0.272\n",
      "             class_109         12         12      0.373      0.583      0.605      0.529\n",
      "             class_110         13         13      0.255     0.0769       0.21      0.183\n",
      "             class_111         12         12      0.487      0.556      0.581      0.505\n",
      "             class_112         13         13        0.5      0.231      0.258      0.232\n",
      "             class_113         18         18       0.59      0.611      0.645       0.46\n",
      "             class_114         17         17      0.727      0.706       0.85      0.706\n",
      "             class_115         21         21      0.585     0.0719      0.221      0.147\n",
      "             class_116         12         12        0.5      0.917      0.929      0.786\n",
      "             class_117         13         13          0          0      0.194      0.142\n",
      "             class_118         18         18      0.313      0.389      0.432      0.317\n",
      "             class_119         13         13      0.455      0.615      0.605      0.514\n",
      "             class_120         11         11      0.312      0.182       0.24      0.197\n",
      "             class_121         21         21      0.426      0.424      0.507      0.389\n",
      "             class_122          9          9          1          0     0.0833     0.0635\n",
      "             class_123         13         13      0.482      0.385      0.373      0.267\n",
      "             class_124         18         18      0.338      0.667       0.39      0.307\n",
      "             class_125         20         20      0.572       0.45      0.476      0.422\n",
      "             class_126         19         19       0.37      0.421      0.335      0.292\n",
      "             class_127          9          9      0.461      0.667      0.415      0.343\n",
      "             class_128         13         13      0.173     0.0769      0.216      0.184\n",
      "             class_129         18         18      0.329       0.41        0.4      0.293\n",
      "             class_130         19         19      0.549      0.421      0.486      0.316\n",
      "             class_131         16         16      0.267          1      0.629      0.568\n",
      "             class_132         18         18      0.412      0.623       0.53      0.435\n",
      "             class_133         18         18      0.692      0.998      0.965       0.87\n",
      "             class_134          9          9      0.283      0.889      0.561      0.415\n",
      "             class_135         25         25      0.481      0.409      0.493      0.381\n",
      "             class_136         17         17      0.428      0.529      0.574      0.464\n",
      "             class_137         18         18      0.441        0.5      0.521      0.431\n",
      "             class_138         12         12      0.294      0.583      0.351      0.306\n",
      "             class_139         20         20      0.451        0.5      0.442      0.382\n",
      "             class_140         16         16          1          0       0.17      0.135\n",
      "             class_141         18         18      0.476        0.5      0.496      0.364\n",
      "             class_142         14         14      0.189      0.214      0.164      0.104\n",
      "             class_143         10         10       0.27        0.7      0.534      0.383\n",
      "             class_144         18         18      0.486      0.278      0.463      0.398\n",
      "             class_145         13         13      0.308      0.344       0.34      0.327\n",
      "             class_146         16         16      0.587       0.25      0.368      0.258\n",
      "             class_147         18         18      0.624      0.097      0.258      0.217\n",
      "             class_148         13         13      0.617      0.251      0.429      0.391\n",
      "             class_149         17         17          1          0     0.0105    0.00495\n",
      "             class_150         13         13      0.737      0.219      0.271      0.223\n",
      "             class_151         15         15      0.268      0.667      0.459      0.375\n",
      "             class_152         16         16      0.534      0.562      0.511      0.376\n",
      "             class_153         15         15      0.426      0.867      0.726      0.651\n",
      "             class_154         23         23       0.45      0.143      0.373      0.326\n",
      "             class_155         13         13       0.37      0.615      0.559      0.398\n",
      "             class_156         19         19      0.695      0.789      0.828      0.573\n",
      "             class_157         15         15      0.612      0.317      0.402       0.33\n",
      "             class_158         11         11      0.433      0.909      0.907      0.835\n",
      "             class_159         16         16      0.196      0.188      0.379      0.315\n",
      "             class_160         11         11      0.528      0.611      0.455      0.396\n",
      "             class_161         17         17      0.294      0.529       0.47      0.414\n",
      "             class_162         20         20      0.772       0.85      0.843       0.59\n",
      "             class_163         16         16       0.46        0.5      0.466      0.398\n",
      "             class_164         18         18      0.606      0.939      0.938      0.827\n",
      "             class_165         16         16      0.329       0.75      0.661      0.519\n",
      "             class_166         19         19      0.305      0.316      0.317      0.279\n",
      "             class_167         17         17      0.182      0.235      0.207      0.172\n",
      "             class_168         12         12      0.467       0.75      0.553      0.325\n",
      "             class_169         20         20      0.545       0.85      0.835      0.745\n",
      "             class_170         16         16      0.513      0.625      0.563      0.402\n",
      "             class_171         15         15      0.605        0.8      0.841      0.719\n",
      "             class_172         23         23      0.289      0.609      0.363      0.292\n",
      "             class_173         17         17      0.513      0.294      0.371       0.33\n",
      "             class_174         12         12      0.351      0.833       0.73      0.607\n",
      "             class_175         14         14      0.332          1       0.93        0.7\n",
      "             class_176          9          9      0.413      0.394      0.421      0.367\n",
      "             class_177         18         18      0.428        0.5      0.352        0.3\n",
      "             class_178         23         23      0.355      0.609       0.58      0.472\n",
      "             class_179         15         15       0.36        0.8      0.697      0.583\n",
      "             class_180         11         11      0.319      0.818      0.752      0.498\n",
      "             class_181         16         16      0.393      0.688      0.523      0.443\n",
      "             class_182         24         24      0.505      0.375      0.479      0.324\n",
      "             class_183         19         19      0.418      0.684      0.501      0.422\n",
      "             class_184         13         13      0.329      0.538       0.44      0.377\n",
      "             class_185         18         18      0.634      0.444      0.464      0.406\n",
      "             class_186         15         15      0.354      0.533      0.368      0.313\n",
      "             class_187         20         20      0.478        0.2      0.266      0.215\n",
      "             class_188         18         18      0.555      0.833      0.727      0.547\n",
      "             class_189         11         11      0.465      0.455      0.465      0.417\n",
      "             class_190         10         10          1          0     0.0772     0.0588\n",
      "             class_191         16         16      0.263      0.562      0.348      0.301\n",
      "             class_192         20         20          1          0     0.0859     0.0716\n",
      "             class_193         16         16      0.275      0.125      0.126     0.0954\n",
      "             class_194         19         19      0.492       0.51      0.518      0.399\n",
      "             class_195         12         12       0.69      0.559      0.534      0.492\n",
      "             class_196         19         19      0.413      0.526      0.421      0.354\n",
      "             class_197         20         20      0.574        0.8      0.708       0.55\n",
      "             class_198         16         16      0.374       0.75      0.581      0.432\n",
      "             class_199         14         14     0.0976     0.0714      0.191       0.16\n",
      "             class_200         20         20      0.506       0.35      0.384      0.263\n",
      "             class_201         15         15      0.548      0.486      0.603      0.535\n",
      "             class_202         15         15      0.328      0.267      0.324      0.259\n",
      "             class_203         18         18      0.398      0.333      0.383      0.261\n",
      "             class_204         22         22      0.532      0.182      0.411       0.32\n",
      "             class_205         21         21      0.401      0.857      0.675      0.531\n",
      "             class_206         16         16      0.241      0.625      0.388      0.342\n",
      "             class_207         15         15      0.221      0.133      0.287      0.245\n",
      "             class_208         16         16      0.156      0.125      0.198      0.153\n",
      "             class_209         23         23      0.718      0.304      0.491      0.347\n",
      "             class_210         10         10          0          0     0.0469     0.0395\n",
      "             class_211         26         26      0.466        0.5      0.492       0.41\n",
      "             class_212         17         17      0.318      0.353      0.434      0.364\n",
      "             class_213         18         18      0.469      0.333      0.467      0.373\n",
      "             class_214         16         16       0.42      0.625      0.589      0.451\n",
      "             class_215         17         17      0.826      0.281      0.485      0.382\n",
      "             class_216         14         14      0.404      0.643      0.605      0.428\n",
      "             class_217         16         16      0.296      0.938      0.835      0.682\n",
      "             class_218         15         15      0.473      0.467      0.381      0.264\n",
      "             class_219         14         14      0.459      0.643        0.6      0.465\n",
      "             class_220         19         19      0.342      0.368      0.253      0.224\n",
      "             class_221         16         16        0.4       0.75       0.59      0.532\n",
      "             class_222         20         20       0.49       0.85      0.618      0.542\n",
      "             class_223         22         22      0.549      0.364      0.492      0.442\n",
      "             class_224         13         13      0.324      0.538      0.448      0.345\n",
      "             class_225          9          9      0.417      0.333      0.403      0.386\n",
      "             class_226         15         15      0.414      0.667      0.538      0.486\n",
      "             class_227         16         16      0.322     0.0625        0.2      0.163\n",
      "             class_228         10         10      0.361      0.174      0.367      0.305\n",
      "             class_229         16         16          0          0      0.129      0.111\n",
      "             class_230         19         19      0.618      0.474      0.482      0.409\n",
      "             class_231         18         18      0.296      0.258      0.366      0.322\n",
      "             class_232         12         12      0.334      0.251      0.264      0.225\n",
      "             class_233         12         12        0.3      0.667      0.399      0.325\n",
      "             class_234         18         18      0.232      0.444      0.208      0.171\n",
      "             class_235         15         15       0.28      0.337      0.289      0.232\n",
      "             class_236         24         24      0.579      0.833      0.642      0.538\n",
      "             class_237         18         18        0.5      0.611      0.622      0.488\n",
      "             class_238         13         13      0.337      0.665      0.318      0.213\n",
      "             class_239         10         10      0.178        0.6      0.395        0.3\n",
      "             class_240         22         22      0.318      0.227      0.329      0.285\n",
      "             class_241         14         14      0.276      0.571      0.438      0.367\n",
      "             class_242         13         13      0.586      0.692      0.667      0.547\n",
      "             class_243         17         17      0.594      0.941      0.807      0.599\n",
      "             class_244         10         10      0.335        0.6       0.49      0.358\n",
      "             class_245         15         15      0.377      0.667      0.446      0.374\n",
      "             class_246         17         17      0.368      0.529      0.564      0.434\n",
      "             class_247         12         12      0.213     0.0918      0.225      0.179\n",
      "             class_248         16         16      0.375      0.188      0.284      0.256\n",
      "             class_249         15         15          1          0     0.0486     0.0364\n",
      "             class_250         17         17      0.703      0.838       0.88      0.677\n",
      "             class_251         14         14      0.378      0.429      0.437      0.318\n",
      "             class_252         18         18      0.831      0.274      0.483      0.404\n",
      "             class_253         10         10      0.561        0.7      0.711      0.471\n",
      "             class_254         10         10      0.683        0.5      0.655      0.523\n",
      "             class_255         16         16      0.487      0.688      0.521      0.436\n",
      "Speed: 0.1ms preprocess, 1.8ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/uec256_kaggle\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,\n",
       "        62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
       "       124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
       "       186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
       "       248, 249, 250, 251, 252, 253, 254, 255])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fd54edf2ad0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0022803,   0.0011401,           0],\n",
       "       [          1,           1,           1, ...,        0.36,        0.36,           0],\n",
       "       [          1,           1,           1, ...,    0.068273,    0.068273,           0],\n",
       "       ...,\n",
       "       [          1,           1,           1, ...,   0.0001556,  7.7798e-05,           0],\n",
       "       [          1,           1,           1, ...,    0.037313,    0.037313,           0],\n",
       "       [        0.8,         0.8,         0.8, ...,     0.04244,     0.04244,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.094168,    0.094168,     0.13441, ...,           0,           0,           0],\n",
       "       [   0.068966,    0.068966,     0.11445, ...,           0,           0,           0],\n",
       "       [   0.041924,    0.041924,    0.064019, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [   0.015411,    0.015411,    0.024654, ...,           0,           0,           0],\n",
       "       [   0.013021,    0.013021,    0.020078, ...,           0,           0,           0],\n",
       "       [   0.034152,    0.034152,    0.048579, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.049522,    0.049522,    0.072346, ...,           1,           1,           1],\n",
       "       [   0.035714,    0.035714,    0.060698, ...,           1,           1,           1],\n",
       "       [   0.021411,    0.021411,    0.033068, ...,           1,           1,           1],\n",
       "       ...,\n",
       "       [   0.007772,    0.007772,    0.012498, ...,           1,           1,           1],\n",
       "       [  0.0065531,   0.0065531,    0.010141, ...,           1,           1,           1],\n",
       "       [   0.017372,    0.017372,    0.024894, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.95652,     0.95652,     0.94565, ...,           0,           0,           0],\n",
       "       [          1,           1,           1, ...,           0,           0,           0],\n",
       "       [          1,           1,           1, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [        0.9,         0.9,         0.9, ...,           0,           0,           0],\n",
       "       [          1,           1,           1, ...,           0,           0,           0],\n",
       "       [          1,           1,           1, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.3822062377346972\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([     0.2939,     0.66769,     0.27413,     0.27208,     0.41623,     0.56434,      0.4453,      0.2985,     0.46577,     0.63049,      0.7274,     0.40798,     0.23265,     0.26499,     0.34211,    0.063656,     0.63474,      0.6331,     0.52609,     0.62989,     0.27818,     0.75327,     0.47281,     0.38573,\n",
       "           0.61092,     0.28072,     0.12498,     0.66571,     0.53348,     0.62625,    0.039667,     0.36172,    0.044091,     0.55168,     0.24942,     0.36904,     0.73087,     0.22706,      0.3201,     0.28662,     0.13362,     0.19198,     0.35964,       0.205,      0.1215,     0.37393,     0.12432,     0.25421,\n",
       "           0.34889,     0.30351,     0.42245,    0.099998,     0.30451,      0.3169,     0.15588,     0.36497,    0.095526,      0.2586,     0.44781,     0.27353,     0.24079,     0.45325,     0.21294,     0.22018,     0.28577,     0.36549,     0.29719,     0.36296,     0.22141,     0.12125,     0.23425,     0.71921,\n",
       "           0.51418,     0.23319,     0.13746,     0.52692,     0.35274,     0.51573,     0.43899,     0.30429,     0.20756,     0.31086,     0.45854,     0.65186,     0.39065,     0.30719,     0.19366,     0.49369,     0.13759,     0.20532,      0.2571,     0.40714,      0.3041,     0.25322,     0.54212,     0.42215,\n",
       "           0.46328,     0.29332,       0.195,     0.38927,     0.24155,     0.67083,     0.40467,     0.54183,     0.54465,     0.52486,     0.58202,     0.50055,     0.27216,     0.52906,     0.18316,     0.50477,     0.23168,     0.45992,     0.70567,     0.14677,     0.78603,     0.14233,     0.31743,     0.51357,\n",
       "           0.19685,     0.38903,    0.063539,     0.26689,     0.30747,      0.4224,     0.29191,     0.34267,     0.18387,     0.29254,     0.31648,     0.56758,     0.43459,     0.87018,      0.4152,     0.38134,      0.4636,      0.4306,     0.30635,     0.38186,     0.13501,     0.36411,     0.10376,     0.38275,\n",
       "           0.39842,     0.32704,      0.2576,     0.21705,     0.39142,   0.0049451,     0.22255,     0.37456,     0.37608,     0.65134,     0.32619,     0.39795,      0.5727,     0.32978,     0.83472,     0.31518,     0.39624,     0.41354,     0.59008,     0.39842,     0.82724,     0.51851,     0.27944,     0.17219,\n",
       "           0.32526,     0.74466,     0.40239,     0.71881,     0.29184,     0.33011,     0.60726,     0.69983,     0.36734,     0.29972,     0.47213,     0.58337,      0.4983,     0.44259,     0.32401,     0.42178,     0.37677,     0.40575,     0.31288,     0.21516,      0.5465,     0.41694,    0.058826,     0.30126,\n",
       "          0.071621,    0.095377,     0.39921,     0.49228,     0.35423,     0.54997,     0.43183,     0.15968,     0.26347,     0.53495,     0.25855,     0.26094,     0.32015,     0.53089,     0.34239,     0.24549,     0.15289,     0.34663,    0.039502,     0.41033,     0.36398,     0.37342,     0.45085,     0.38217,\n",
       "           0.42777,     0.68217,     0.26427,     0.46465,     0.22411,     0.53247,     0.54209,     0.44198,     0.34546,     0.38618,     0.48637,     0.16331,     0.30502,     0.11106,     0.40869,     0.32207,     0.22527,     0.32519,     0.17116,     0.23195,     0.53812,     0.48839,     0.21279,     0.30026,\n",
       "           0.28511,     0.36693,     0.54668,     0.59904,     0.35776,     0.37381,     0.43417,     0.17895,     0.25579,    0.036387,     0.67708,     0.31845,     0.40414,     0.47124,     0.52265,     0.43625])\n",
       "names: {0: 'class_0', 1: 'class_1', 2: 'class_2', 3: 'class_3', 4: 'class_4', 5: 'class_5', 6: 'class_6', 7: 'class_7', 8: 'class_8', 9: 'class_9', 10: 'class_10', 11: 'class_11', 12: 'class_12', 13: 'class_13', 14: 'class_14', 15: 'class_15', 16: 'class_16', 17: 'class_17', 18: 'class_18', 19: 'class_19', 20: 'class_20', 21: 'class_21', 22: 'class_22', 23: 'class_23', 24: 'class_24', 25: 'class_25', 26: 'class_26', 27: 'class_27', 28: 'class_28', 29: 'class_29', 30: 'class_30', 31: 'class_31', 32: 'class_32', 33: 'class_33', 34: 'class_34', 35: 'class_35', 36: 'class_36', 37: 'class_37', 38: 'class_38', 39: 'class_39', 40: 'class_40', 41: 'class_41', 42: 'class_42', 43: 'class_43', 44: 'class_44', 45: 'class_45', 46: 'class_46', 47: 'class_47', 48: 'class_48', 49: 'class_49', 50: 'class_50', 51: 'class_51', 52: 'class_52', 53: 'class_53', 54: 'class_54', 55: 'class_55', 56: 'class_56', 57: 'class_57', 58: 'class_58', 59: 'class_59', 60: 'class_60', 61: 'class_61', 62: 'class_62', 63: 'class_63', 64: 'class_64', 65: 'class_65', 66: 'class_66', 67: 'class_67', 68: 'class_68', 69: 'class_69', 70: 'class_70', 71: 'class_71', 72: 'class_72', 73: 'class_73', 74: 'class_74', 75: 'class_75', 76: 'class_76', 77: 'class_77', 78: 'class_78', 79: 'class_79', 80: 'class_80', 81: 'class_81', 82: 'class_82', 83: 'class_83', 84: 'class_84', 85: 'class_85', 86: 'class_86', 87: 'class_87', 88: 'class_88', 89: 'class_89', 90: 'class_90', 91: 'class_91', 92: 'class_92', 93: 'class_93', 94: 'class_94', 95: 'class_95', 96: 'class_96', 97: 'class_97', 98: 'class_98', 99: 'class_99', 100: 'class_100', 101: 'class_101', 102: 'class_102', 103: 'class_103', 104: 'class_104', 105: 'class_105', 106: 'class_106', 107: 'class_107', 108: 'class_108', 109: 'class_109', 110: 'class_110', 111: 'class_111', 112: 'class_112', 113: 'class_113', 114: 'class_114', 115: 'class_115', 116: 'class_116', 117: 'class_117', 118: 'class_118', 119: 'class_119', 120: 'class_120', 121: 'class_121', 122: 'class_122', 123: 'class_123', 124: 'class_124', 125: 'class_125', 126: 'class_126', 127: 'class_127', 128: 'class_128', 129: 'class_129', 130: 'class_130', 131: 'class_131', 132: 'class_132', 133: 'class_133', 134: 'class_134', 135: 'class_135', 136: 'class_136', 137: 'class_137', 138: 'class_138', 139: 'class_139', 140: 'class_140', 141: 'class_141', 142: 'class_142', 143: 'class_143', 144: 'class_144', 145: 'class_145', 146: 'class_146', 147: 'class_147', 148: 'class_148', 149: 'class_149', 150: 'class_150', 151: 'class_151', 152: 'class_152', 153: 'class_153', 154: 'class_154', 155: 'class_155', 156: 'class_156', 157: 'class_157', 158: 'class_158', 159: 'class_159', 160: 'class_160', 161: 'class_161', 162: 'class_162', 163: 'class_163', 164: 'class_164', 165: 'class_165', 166: 'class_166', 167: 'class_167', 168: 'class_168', 169: 'class_169', 170: 'class_170', 171: 'class_171', 172: 'class_172', 173: 'class_173', 174: 'class_174', 175: 'class_175', 176: 'class_176', 177: 'class_177', 178: 'class_178', 179: 'class_179', 180: 'class_180', 181: 'class_181', 182: 'class_182', 183: 'class_183', 184: 'class_184', 185: 'class_185', 186: 'class_186', 187: 'class_187', 188: 'class_188', 189: 'class_189', 190: 'class_190', 191: 'class_191', 192: 'class_192', 193: 'class_193', 194: 'class_194', 195: 'class_195', 196: 'class_196', 197: 'class_197', 198: 'class_198', 199: 'class_199', 200: 'class_200', 201: 'class_201', 202: 'class_202', 203: 'class_203', 204: 'class_204', 205: 'class_205', 206: 'class_206', 207: 'class_207', 208: 'class_208', 209: 'class_209', 210: 'class_210', 211: 'class_211', 212: 'class_212', 213: 'class_213', 214: 'class_214', 215: 'class_215', 216: 'class_216', 217: 'class_217', 218: 'class_218', 219: 'class_219', 220: 'class_220', 221: 'class_221', 222: 'class_222', 223: 'class_223', 224: 'class_224', 225: 'class_225', 226: 'class_226', 227: 'class_227', 228: 'class_228', 229: 'class_229', 230: 'class_230', 231: 'class_231', 232: 'class_232', 233: 'class_233', 234: 'class_234', 235: 'class_235', 236: 'class_236', 237: 'class_237', 238: 'class_238', 239: 'class_239', 240: 'class_240', 241: 'class_241', 242: 'class_242', 243: 'class_243', 244: 'class_244', 245: 'class_245', 246: 'class_246', 247: 'class_247', 248: 'class_248', 249: 'class_249', 250: 'class_250', 251: 'class_251', 252: 'class_252', 253: 'class_253', 254: 'class_254', 255: 'class_255'}\n",
       "nt_per_class: array([ 92,  18,  17,  19,  18,  35,  30,  13,  29,  19,  16,  40,  18,  16,  15,  16,  39,  23,  27,  29,  18,  21,  52,  24,  15,  22,  16,  21,  12,  24,  18,  21,  13,  18,  16, 112,  20,  16,  19,  15,  16,  20,  12,   9,  17,  17,  17,  24,  26,  20,  19,  15,  22,  22,  17,  23,  15,  16,  18,  21,  16,  13,\n",
       "        21,  18,  16,  16,  22,  32,  26,  25,  16,  21,  26,  20,  12,  21,  13,  19,  22,  14,  21,  20,  24,  16,  21,  12,  63,  12,  14,  14,  26,  30,  20,  31,  13,  25,  16,  28,  18,  17,  15,  23,  16,  25,  22,  20,  21,  13,  20,  12,  13,  12,  13,  18,  17,  21,  12,  13,  18,  13,  11,  21,   9,  13,\n",
       "        18,  20,  19,   9,  13,  18,  19,  16,  18,  18,   9,  25,  17,  18,  12,  20,  16,  18,  14,  10,  18,  13,  16,  18,  13,  17,  13,  15,  16,  15,  23,  13,  19,  15,  11,  16,  11,  17,  20,  16,  18,  16,  19,  17,  12,  20,  16,  15,  23,  17,  12,  14,   9,  18,  23,  15,  11,  16,  24,  19,  13,  18,\n",
       "        15,  20,  18,  11,  10,  16,  20,  16,  19,  12,  19,  20,  16,  14,  20,  15,  15,  18,  22,  21,  16,  15,  16,  23,  10,  26,  17,  18,  16,  17,  14,  16,  15,  14,  19,  16,  20,  22,  13,   9,  15,  16,  10,  16,  19,  18,  12,  12,  18,  15,  24,  18,  13,  10,  22,  14,  13,  17,  10,  15,  17,  12,\n",
       "        16,  15,  17,  14,  18,  10,  10,  16])\n",
       "nt_per_image: array([ 92,  18,  17,  19,  18,  35,  30,  13,  29,  19,  16,  40,  18,  16,  15,  16,  39,  23,  27,  29,  18,  21,  52,  24,  15,  22,  16,  21,  12,  24,  18,  21,  13,  18,  16, 112,  20,  16,  19,  15,  16,  20,  12,   9,  17,  17,  17,  24,  26,  20,  19,  15,  22,  22,  17,  23,  15,  16,  18,  21,  16,  13,\n",
       "        21,  18,  16,  16,  22,  32,  26,  25,  16,  21,  26,  20,  12,  21,  13,  19,  22,  14,  21,  20,  24,  16,  21,  12,  63,  12,  14,  14,  26,  30,  20,  31,  13,  25,  16,  28,  18,  17,  15,  23,  16,  25,  22,  20,  21,  13,  20,  12,  13,  12,  13,  18,  17,  21,  12,  13,  18,  13,  11,  21,   9,  13,\n",
       "        18,  20,  19,   9,  13,  18,  19,  16,  18,  18,   9,  25,  17,  18,  12,  20,  16,  18,  14,  10,  18,  13,  16,  18,  13,  17,  13,  15,  16,  15,  23,  13,  19,  15,  11,  16,  11,  17,  20,  16,  18,  16,  19,  17,  12,  20,  16,  15,  23,  17,  12,  14,   9,  18,  23,  15,  11,  16,  24,  19,  13,  18,\n",
       "        15,  20,  18,  11,  10,  16,  20,  16,  19,  12,  19,  20,  16,  14,  20,  15,  15,  18,  22,  21,  16,  15,  16,  23,  10,  26,  17,  18,  16,  17,  14,  16,  15,  14,  19,  16,  20,  22,  13,   9,  15,  16,  10,  16,  19,  18,  12,  12,  18,  15,  24,  18,  13,  10,  22,  14,  13,  17,  10,  15,  17,  12,\n",
       "        16,  15,  17,  14,  18,  10,  10,  16])\n",
       "results_dict: {'metrics/precision(B)': 0.48165930666905643, 'metrics/recall(B)': 0.4742428236979083, 'metrics/mAP50(B)': 0.47980231762963266, 'metrics/mAP50-95(B)': 0.3713622288574821, 'fitness': 0.3822062377346972}\n",
       "speed: {'preprocess': 0.0731999292785361, 'inference': 1.8292209780443207, 'loss': 0.0002725224804240278, 'postprocess': 0.9996800791613543}\n",
       "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load pre-trained YOLOv8n (Nano) model â€” fastest for testing\n",
    "# model = YOLO('yolov8n.pt')  # you can try yolov8s.pt or yolov8m.pt for better accuracy\n",
    "\n",
    "# # Start training\n",
    "# model.train(\n",
    "#     data='/kaggle/working/dataset.yaml',\n",
    "#     epochs=30,\n",
    "#     imgsz=416,\n",
    "#     batch=16,\n",
    "#     name='uec256_yolo_model',\n",
    "#     project='food_nutrition_project'\n",
    "# )\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "model.train(\n",
    "    data='/kaggle/working/dataset.yaml',\n",
    "    epochs=20,\n",
    "    imgsz=416,\n",
    "    batch=16,\n",
    "    name='uec256_kaggle',\n",
    "    project='/kaggle/working'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results_csv = '/kaggle/working/uec256_kaggle/results.csv'\n",
    "df = pd.read_csv(results_csv)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(df['metrics/precision(B)'], label='Precision')\n",
    "plt.plot(df['metrics/recall(B)'], label='Recall')\n",
    "plt.plot(df['metrics/mAP50(B)'], label='mAP@0.5')\n",
    "plt.plot(df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95')\n",
    "plt.title(\"Validation Performance\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(df['train/box_loss'], label='Train Box Loss')\n",
    "plt.plot(df['val/box_loss'], label='Val Box Loss')\n",
    "plt.plot(df['train/cls_loss'], label='Train Cls Loss', linestyle='--')\n",
    "plt.plot(df['val/cls_loss'], label='Val Cls Loss', linestyle='--')\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_path = '/kaggle/working/dataset/images/test'\n",
    "results = model.predict(\n",
    "    source=test_path,\n",
    "    save=True,\n",
    "    save_txt=True,\n",
    "    name='test_preds',\n",
    "    project='/kaggle/working'\n",
    ")\n",
    "\n",
    "print(\"âœ… Predictions saved in /kaggle/working/test_preds/\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7669974,
     "sourceId": 12178320,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
